{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# First Draft: A Project to Optimize the Commute"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###This project started out with one goal: to optimize travel times for everyday commuters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>While people have access to real-time traffic information (e.g. google maps), there is no application that helps you predict travel times in advance. Sure enough, people have google maps. They can also sometimes guess what time is best to leave for work in the morning based off of past experience. But what if we could somewhat accurately predict travel duration for certain routes using historical traffic data?</p>\n",
    "<p>In order to make a prediction, we would require at least three variables: 1) the route (an origin/destination pair) 2) departure time and 3) estimated travel time. With this data, one could build a mulitple linear regression model where departure time is the input variable and predicted travel duration is the response variable.</p>\n",
    "<p>Unfortunately, historical traffic data is unavailable to the open source community. Furthermore, Maps APIs such as Google typically have quota limits for the number of routes that one can query within a given time period. Given such constraints, I have defined a small list of residential neighborhoods (listed below) and work neighborhoods (also listed below) to act as origins and destinations--depending on the time of day--for the purposes of this project</p>\n",
    "<p>I have set up two sets of python scripts which collect information every fifteen minutes in the morning for commuters traveling to work and every fifteen minutes in the afternoonoon for people traveling home. For instance, every 15 minutes between the hours of 4am and 11am, I have a script that queries the google maps API for public transit travel duration from each residential location to each work location. Every 15 minutes between the hours of 2pm and 9pm, I have a script that queries the google maps API for public transit travel duration from each work location to each residential location. Since Google's APIs do not provide (free) real-time traffic data, I had to create separate scripts to query Microsoft's Bing maps, which offers free real-time traffic information. All information obtained from the Google Maps and Bing Maps APIs is stored in a MySQL database.</p>\n",
    "<p>Unfortunately, most of my time has been spent building the scripts and infrastructure to collect data. However, as information flows in, I should be able to start building the model.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Below are the data points and display names for... \n",
    "#origins/destinations in residential and work locations\n",
    "pacific_heights = \"Pacific Heights, San Francisco, CA\"\n",
    "outer_richmond = \"Outer Richmond, San+Francisco, CA\"\n",
    "outer_sunset = \"Outer Sunset, San Francisco, CA\"\n",
    "mission_district = \"Mission District, San Francisco, CA\"\n",
    "noe_valley = \"Noe Valley, San+Francisco, CA\"\n",
    "berkeley = \"Berkeley, CA\"\n",
    "oakland = \"Oakland, CA\"\n",
    "financial_district = \"Financial District, San Francisco, CA\"\n",
    "mountain_view = \"Mountain View, CA\"\n",
    "residential_neighborhoods = [russian_hill, north_beach, pacific_heights, outer_richmond,\\\n",
    "                            outer_sunset, mission_district, noe_valley,\\\n",
    "                            oakland, berkeley]\n",
    "work_neighborhoods = [oakland, financial_district, mountain_view]\n",
    "residential_coordinates = ['37.8010963,-122.4195558', '37.8060532,-122.4103311',\\\n",
    "                        '37.7925153,-122.4382307', '37.777677,-122.49531',\\\n",
    "                         '37.755445,-122.494069', '37.7598648,-122.4147977',\\\n",
    "                            '37.7502378,-122.4337029', '37.8043637,-122.2711137',\\\n",
    "                             '37.8715926,-122.272747']\n",
    "work_coordinates = ['37.8043637,-122.2711137', '37.7945742,-122.3999445',\\\n",
    "                    '37.3860517,-122.0838511']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Below is the cron code used to automate the process of querying...\n",
    "#the Google Maps and Bing Maps APIs in the morning and afternoon\n",
    "###morning queries\n",
    "0,15,30,45 11,12,13,14,15,16,17 * * * python /home/ec2-user/DAT_SF_13_homework/final_project/iter_gmaps_morn.py\n",
    "0,15,30,45 11,12,13,14,15,16,17 * * * python /home/ec2-user/DAT_SF_13_homework/final_project/iter_mmaps_morn.py\n",
    "0 18 * * * python /home/ec2-user/DAT_SF_13_homework/final_project/iter_gmaps_morn.py\n",
    "0 18 * * * python /home/ec2-user/DAT_SF_13_homework/final_project/iter_mmaps_morn.py\n",
    "###afternoon queries\n",
    "0,15,30,45 21,22,23,0,1,2,3 * * * python /home/ec2-user/DAT_SF_13_homework/final_project/iter_gmaps_morn.py\n",
    "0,15,30,45 21,22,23,0,1,2,3 * * * python /home/ec2-user/DAT_SF_13_homework/final_project/iter_mmaps_morn.py\n",
    "0 4 * * * python /home/ec2-user/DAT_SF_13_homework/final_project/iter_gmaps_morn.py\n",
    "0 4 * * * python /home/ec2-user/DAT_SF_13_homework/final_project/iter_mmaps_morn.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Below is the script used to query Bing Maps for driving time information in the morning.\n",
    "#Please note: the script will only run on the server and will not work in this ipython Notebook\n",
    "\n",
    "#!/Users/gpnaifeh/anaconda/bin/python2.7\n",
    "import json\n",
    "import urllib\n",
    "import urllib2\n",
    "#import pandas as pd\n",
    "import numpy as np\n",
    "from numpy import division\n",
    "import MySQLdb as mdb\n",
    "from datetime import datetime\n",
    "import MySQL_data_file as MySQL_data\n",
    "import query_data_file\n",
    "\n",
    "#Neighborhoods to be used\n",
    "pacific_heights = \"Pacific Heights, San Francisco, CA\"\n",
    "outer_richmond = \"Outer Richmond, San+Francisco, CA\"\n",
    "outer_sunset = \"Outer Sunset, San Francisco, CA\"\n",
    "mission_district = \"Mission District, San Francisco, CA\"\n",
    "noe_valley = \"Noe Valley, San+Francisco, CA\"\n",
    "berkeley = \"Berkeley, CA\"\n",
    "oakland = \"Oakland, CA\"\n",
    "financial_district = \"Financial District, San Francisco, CA\"\n",
    "mountain_view = \"Mountain View, CA\"\n",
    "#russian_hill = \"Russian Hill, San Francisco, CA\"\n",
    "#north_beach = \"North Beach, San Francisco, CA\"\n",
    "\n",
    "residential_neighborhoods = [russian_hill, north_beach, pacific_heights, outer_richmond,\\\n",
    "                            outer_sunset, mission_district, noe_valley,\\\n",
    "                            oakland, berkeley]\n",
    "work_neighborhoods = [oakland, financial_district, mountain_view]\n",
    "residential_coordinates = ['37.8010963,-122.4195558', '37.8060532,-122.4103311',\\\n",
    "                        '37.7925153,-122.4382307', '37.777677,-122.49531',\\\n",
    "                         '37.755445,-122.494069', '37.7598648,-122.4147977',\\\n",
    "                            '37.7502378,-122.4337029', '37.8043637,-122.2711137',\\\n",
    "                             '37.8715926,-122.272747']\n",
    "work_coordinates = ['37.8043637,-122.2711137', '37.7945742,-122.3999445',\\\n",
    "                    '37.3860517,-122.0838511']\n",
    "\n",
    "\n",
    "#connect to database and execute query\n",
    "#does not return anything\n",
    "def query_db(command):\n",
    "    con = mdb.connect(MySQL_data.my_sql_host, MySQL_data.my_sql_user,\\\n",
    "                        MySQL_data.my_sql_passwd,\\\n",
    "                        MySQL_data.my_sql_database)\n",
    "    cur = con.cursor()\n",
    "    cur.execute(command)\n",
    "    con.commit()\n",
    "    con.close()\n",
    "\n",
    "\n",
    "#query the Bing maps API wiht a given origin and destination\n",
    "#returns a json object\n",
    "def queryMmaps(query_origin, query_destination, mmaps_api_key):\n",
    "    this_url = \"\"\"http://dev.virtualearth.net/REST/v1/Routes?\\\n",
    "wayPoint.1={}&\\\n",
    "wayPoint.2={}&\\\n",
    "optimize=timeWithTraffic&\\\n",
    "key={}\"\"\".\\\n",
    "format(query_origin, query_destination, query_data_file.mmaps_api_key)\n",
    "    mmaps_query = urllib2.urlopen(this_url)\n",
    "    query_result = json.loads(mmaps_query.read())\n",
    "    return query_result\n",
    "\n",
    "\n",
    "#function that takes the json object and returns an\n",
    "#np array to be entered into the database\n",
    "def createEntry(query_result, query_time, query_origin, \\\n",
    "                    query_destination, travel_mode):\n",
    "    if 'statusDescription' in query_result:\n",
    "        if query_result['statusDescription'] != 'OK':\n",
    "            print \"There is an issue with the high level status description.\\\n",
    "                    It is currently listed as {}\".format(status_description)\n",
    "    travel_duration = \"NULL\"\n",
    "    travel_duration_traffic = \"NULL\"\n",
    "    travel_distance = \"NULL\"\n",
    "    traffic_congestion = \"NULL\"\n",
    "    try:\n",
    "        resource_sets_dict = query_result['resourceSets'][0]#use '0' as an index because the dictionary object is embedded in a list\n",
    "        resources_dict = resource_sets_dict['resources'][0]#use '0' as an index because the dictionary object is embedded in a list\n",
    "        if 'travelDuration' in resources_dict:\n",
    "            travel_duration = resources_dict['travelDuration']\n",
    "        if 'travelDurationTraffic' in resources_dict:\n",
    "            travel_duration_traffic = resources_dict['travelDurationTraffic']\n",
    "        if 'travelDistance' in resources_dict:\n",
    "            travel_distance = resources_dict['travelDistance']\n",
    "        if 'trafficCongestion' in resources_dict:\n",
    "            traffic_congestion = resources_dict['trafficCongestion']\n",
    "    except:\n",
    "        print \"Exception triggered when trying to query 'resources_dict' object\"\n",
    "    entry_array = np.array([query_time, query_origin,\\\n",
    "                            query_destination, travel_mode, travel_duration,\\\n",
    "                            travel_duration_traffic, travel_distance,\\\n",
    "                            traffic_congestion])\n",
    "    return entry_array\n",
    "\n",
    "\n",
    "def saveToDatabase(array_of_entries):\n",
    "    for array in array_of_entries:\n",
    "        query_db(\"\"\"INSERT INTO mmaps_data_local(datetime,origins,destinations,travel_mode,duration,duration_traffic,distance,congestion)\n",
    "                    VALUES ('{}','{}','{}','{}',{},{},{},'{}')\"\"\"\\\n",
    "                    .format(array[0],array[1],array[2],array[3], array[4],array[5],array[6],array[7]))\n",
    "\n",
    "\n",
    "def run_trip (start_neighborhoods, start_coordinates,\\\n",
    "                end_neighborhoods, end_coordinates):\n",
    "    array_of_entries = np.array([])\n",
    "    for i in np.arange(len(start_neighborhoods)):\n",
    "        for n in np.arange(len(end_neighborhoods)):\n",
    "            if start_neighborhoods[i] != end_neighborhoods[n]:\n",
    "                query_origin = start_coordinates[i]\n",
    "                query_destination = end_coordinates[n]\n",
    "                mmaps_api_key = query_data_file.mmaps_api_key\n",
    "                query_time = datetime.now().isoformat(' ')\n",
    "                travel_mode = \"driving\"\n",
    "                query_result = queryMmaps(query_origin, query_destination,\\\n",
    "                                            mmaps_api_key)\n",
    "                entry_array = createEntry(query_result, query_time,\\\n",
    "                                            start_neighborhoods[i],\\\n",
    "                                            end_neighborhoods[n],\\\n",
    "                                            travel_mode)\n",
    "                array_of_entries = np.append(array_of_entries,\\\n",
    "                                                entry_array, axis=0)\n",
    "    number_of_columns = 8\n",
    "    number_of_rows = (len(array_of_entries))/number_of_columns\n",
    "    array_of_entries = np.reshape(array_of_entries,\\\n",
    "                                    (number_of_rows, number_of_columns))\n",
    "    saveToDatabase(array_of_entries)\n",
    "\n",
    "\n",
    "run_trip(residential_neighborhoods, residential_coordinates, work_neighborhoods, work_coordinates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Below is the script used to query google maps for transit data in the morning\n",
    "#Please note: the script will only run on the server and will not work in this ipython Notebook\n",
    "\n",
    "#!/Users/gpnaifeh/anaconda/bin/python2.7\n",
    "\n",
    "import json\n",
    "import urllib2\n",
    "#import pandas as pd\n",
    "import numpy as np\n",
    "from numpy import division\n",
    "import MySQLdb as mdb\n",
    "from datetime import datetime\n",
    "import MySQL_data_file as MySQL_data\n",
    "import query_data_file\n",
    "\n",
    "#districts\n",
    "russian_hill = \"Russian+Hill+San+Francisco+CA\"\n",
    "north_beach = \"North+Beach+San+Francisco+CA\"\n",
    "pacific_heights = \"Pacific+Heights+San+Francisco+CA\"\n",
    "outer_richmond = \"Outer+Richmond+San+Francisco+CA\"\n",
    "outer_sunset = \"Outer+Sunset+San+Francisco+CA\"\n",
    "mission_district = \"Mission+District+San+Francisco+CA\"\n",
    "noe_valley = \"Noe+Valley+San+Francisco+CA\"\n",
    "\n",
    "oakland = \"Oakland+CA\"\n",
    "berkeley = \"Berkeley+CA\"\n",
    "\n",
    "soma_district = \"SoMA+San+Francisco+CA\"\n",
    "financial_district = \"Financial+District+San+Francisco+CA\"\n",
    "mountain_view = \"Mountain+View+CA\"\n",
    "\n",
    "def add_districts(list_of_districts):\n",
    "    district_list_string = ''\n",
    "    for x in list_of_districts:\n",
    "        district_list_string = district_list_string + x + \"|\"\n",
    "    return district_list_string\n",
    "\n",
    "current_origins = add_districts([add_districts([russian_hill, north_beach,\\\n",
    "                            pacific_heights, outer_richmond,\\\n",
    "                            outer_sunset, mission_district, noe_valley,\\\n",
    "                            oakland, berkeley])\n",
    "current_destinations = add_districts([oakland, financial_district, mountain_view])\n",
    "\n",
    "travel_mode = \"transit\"\n",
    "\n",
    "gmaps_query = urllib2.urlopen(\"\"\"\n",
    "https://maps.googleapis.com/maps/api/\\\n",
    "distancematrix/json?\\\n",
    "origins={}&\\\n",
    "destinations={}&\\\n",
    "mode={}&\\\n",
    "key={}&\\\n",
    "departure_time=now\"\"\".\\\n",
    "format(current_origins, current_destinations, travel_mode, query_data_file.gmaps_api_key))\n",
    "\n",
    "query_result = json.loads(gmaps_query.read())\n",
    "\n",
    "array_of_entries = np.array([])\n",
    "query_time = datetime.now().isoformat(' ')\n",
    "query_origins = np.array(query_result['origin_addresses'])\n",
    "query_destinations = np.array(query_result['destination_addresses'])\n",
    "#iterate through and print all trips\n",
    "if query_result['status'] == 'OK':\n",
    "    query_rows = query_result['rows']\n",
    "    for i in np.arange(len(query_rows)):\n",
    "        query_elements = query_rows[i]['elements']\n",
    "        for n in np.arange(len(query_elements)):\n",
    "            if query_origins[i] != query_destinations[n]:\n",
    "                try:\n",
    "                    #print \"Trip from {} to {}\".format(query_origins[i],query_destinations[n])\n",
    "                    if 'duration' in query_elements[n]:\n",
    "                        this_trip_duration = query_elements[n]['duration']['value']\n",
    "                    else:\n",
    "                        this_trip_duration = \"NULL\"\n",
    "                    if 'distance' in query_elements[n]:\n",
    "                        this_trip_distance = query_elements[n]['distance']['value']\n",
    "                    else:\n",
    "                        this_trip_distance = \"NULL\"\n",
    "                    if 'fare' in query_elements[n]:\n",
    "                        this_trip_fare = query_elements[n]['fare']['value']\n",
    "                    else:\n",
    "                        this_trip_fare = \"NULL\"\n",
    "                    #print \"Duration:\", this_trip_duration\n",
    "                    #print \"Distance:\", this_trip_distance\n",
    "                    #print \"Fare:\", this_trip_fare\n",
    "                except:\n",
    "                    #print error?\n",
    "                    print \"Exception triggered at the element level\"\n",
    "                    if (query_elements[n]['status'] != \"OK\"):\n",
    "                        print \"Element status is: {}\".format(query_elements[n]['status'])\n",
    "                entry_array = np.array([query_time, query_origins[i],\\\n",
    "                                        query_destinations[n], travel_mode,\n",
    "                                        this_trip_duration, this_trip_distance,\\\n",
    "                                        this_trip_fare])\n",
    "                array_of_entries = np.append(array_of_entries, entry_array, axis=0)\n",
    "else:\n",
    "    print 'The status of the query was not listed as \"Ok\"'\n",
    "    print 'The status of the query was listed as: {}'.format(query_result['status'])\n",
    "#print datetime.now().isoformat(' ')\n",
    "array_of_entries = np.reshape(array_of_entries, (len(array_of_entries)/7,7))\n",
    "\n",
    "#connect to database\n",
    "def query_db(command):\n",
    "    con = mdb.connect(MySQL_data.my_sql_host, MySQL_data.my_sql_user, \\\n",
    "                        MySQL_data.my_sql_passwd,\\\n",
    "                        MySQL_data.my_sql_database)\n",
    "    cur = con.cursor()\n",
    "    cur.execute(command)\n",
    "    con.commit()\n",
    "    con.close()\n",
    "\n",
    "for array in array_of_entries:\n",
    "    query_db(\"\"\"INSERT INTO gmaps_data_local\\\n",
    "                (datetime,origins,destinations,travel_mode,duration,distance,fare)\n",
    "                VALUES ('{}','{}','{}','{}',{},{},{})\"\"\"\\\n",
    "                .format(array[0],array[1],array[2],array[3], array[4],array[5],array[6]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
